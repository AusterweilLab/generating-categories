\documentclass[10pt,letterpaper]{article}

\usepackage{cogsci}
\usepackage{pslatex}
\usepackage{amsmath}
\usepackage[natbibapa]{apacite}

% set up PGF
\usepackage{pgfplots}
\pgfplotsset{compat=1.13}
\newcommand\inputpgf[2]{{
\let\pgfimageWithoutPath\pgfimage
\renewcommand{\pgfimage}[2][]{\pgfimageWithoutPath[##1]{#1/##2}}
\input{#1/#2}
}}




\title{PACKER: An Exemplar Model of Category Generation}
 %JLA: I like an exemplar model of category generation better, the only issue is there already is an exemplar model. Need to figure out how to get PACKER or something like it as the acronym...
 % 		is that Jern & Kemp 2013 named their own exemplar model for category generation  ("copy-and-tweak"). We need to implement something like it...


\author{
{ \large \bf Nolan Conaway (nconaway@wisc.edu) } \\
{ \large \bf Joseph L. Austerweil (austerweil@wisc.edu) } \\
Department of Psychology, 1202 W. Johnson Street \\
Madison, WI 53706 USA
}


\begin{document}

\maketitle

\begin{abstract}
FILLER

\textbf{Keywords:} 
Categorization; etc
\end{abstract}

\section{Introduction}

One of the most intriguing capabilities of human cognition is the ability to creatively generate new ideas and concepts. % Some statement about how often people use concepts creatively, prevalence, etc
The creative use of knowledge has, however, scarcely been the subject of scientific inquiry in the field of categorization. Most research on concepts and categorization has conformed to a traditional artificial classification learning paradigm \citep{kurtz2015human}, wherein the primary use of category knowledge is to discriminate between two or more experimenter-defined classes.

In one of the earliest explorations on the creative use of conceptual knowledge, Ward \& colleagues \citep{marsh1999inadvertent,smith1993constraining,ward2002role,ward1994structured} provided clear evidence of the role of prior knowledge in concept generation. In a canonical study, \citet{ward1994structured} asked participants to draw and describe novel species of plants and animals that might exist on other planets. Generation was strongly constrained by prior knowledge of Earth plants and animals: people generated alien species using the same structural forms found on Earth (e.g., eyes, legs, wings), exemplars tended to obey the same feature correlations observed on Earth (e.g., feathers tended to co-occur with wings), and exemplars drawn from the same species were less variable than animals drawn from different species (as is the case on Earth). 

% early formal models, intro copy and tweak. [joe: did you ever get those papers?]

In a more recent report, \citet{jern2013probabilistic} developed a hierarchical model capable of explaining the influence of prior knowledge observed by \citet{ward1994structured}. In their model, categories are represented as distributions in multidimensional space, where known exemplars are assumed to have been generated from the underlying category distribution. Category distributions are in turn thought to be generated by an underlying domain distribution, representing common distributional characteristics of known categories (e.g., feature variance, feature correlations). When asked to generate exemplars from a novel category, people are thought to sample a new category from the domain distribution, and then sample exemplars from the category distribution. Thus, the generated exemplars tend to obey the same distributional properties of known categories. 

\citet{jern2013probabilistic} reported several experiments in support of their model's predictions. In their paradigm, participants are first exposed to members from a set of known categories within a $k$-dimensional feature space (in their experiments, $k=3$). After observing the assigned examples, participants are asked to generate exemplars from a new category within the domain. Participants presented with $k$ scales that can be used to adjust the feature values of the generated stimulus, and are given unlimited time to create each example. As in the classic \cite{ward1994structured} experiment, \citet{jern2013probabilistic} found that people generated categories possessing the same feature correlations as the known categories in the domain.


\section{PACKER: An Exemplar Model}

The work presented by Ward \& Colleagues, as well as that of \citet{jern2013probabilistic}, undoubtedly captures a core principle of the creative use of conceptual knowledge: category generation is informed by the distributional characteristics of known concepts in the target domain. However, this work fails to describe the inverse: how do generated categories \textit{differ} from known categories? In this paper, we introduce a novel exemplar-based approach to category generation, the PACKER model (\textit{Producing Alike and Contrasting Knowledge using Exemplar Representations}), which creates new categories by balancing two constraints: (1) new categories should be different from known categories (minimizing between-class similarity), and (2) new categories should be internally coherent (maximizing within-class similarity). 

% Is this evident? "we are not suggesting Jern \& Kemp have failed to capture a core aspect of generation, but that there are other properties that can be explained through one of the field's oldest traditions."

The PACKER model is in many senses an extension of the highly influential Generalized Context Model of category learning (GCM; \citealp{nosofsky1984choice}). The model assumes that each category is represented by a collection of exemplars within in a $k$-dimensional stimulus space, and that generation is constrained by both similarity to members of the category being generated as well as similarity to members of other categories. 

As in the GCM, the similarity between two examples, $s(x_i, x_j)$, is defined as an inverse-exponential function of distance:
\begin{equation}
  s(x_i,x_j) = exp( -c \sum_{k}{|x_{ik} - x_{jk}|}w_k ) 
\end{equation}
where $w_k$ is a vector of attention parameters ($\sum_k{w_k} = 1$), weighting to the importance of each feature in the similarity computation. The $c$ parameter controls the specificity of examples: larger values of $c$ produce more \textit{specific} representations (exemplars that do not generalize broadly). The attention weights are of interest in explaining individual differences in generation strategy (discussed below), but for our formal simulations they are set uniformly.

When prompted to generate a new example, the model considers both the summed similarity to examples from other categories as well as the summed similarity to examples in the target category. More formally, the summed similarity $ss$ between generation candidate $y$ and the model's stored exemplars $x_j$ can be computed as:
\begin{equation}
  ss(y, x_j) = \sum_j{f_j s(y, x_j)}
\end{equation}
where $f_j$ is a function specifying each example's degree of contribution toward generation. Although $f_j$ may be set arbitrarily, in PACKER it is set according to class assignment. For known members of contrast categories, $f_j = -\phi$. For known members of the target category, $f_j = \gamma$. $\phi$ and $\gamma$ are thus free parameters ($\geq 0$) controlling the contribution of target- and contrast-category similarity to generation. Larger values for either parameter produce greater consideration of either type of similarity. When $\phi = \gamma$, similarity to contrast categories is effectively subtracted from similarity to the target category. Negative values for $ss(y, x_j)$ would then indicate that $y$ is more similar to members of contrast categories, and positive values indicate $y$ is more similar to members of the target category.

% NOTE: Maybe we should use a different term for summed similarity? Or maybe just indicate specifically how this deviates from classification in the GCM.

The probability that a given candidate $y$ will be generated is evaluated using the \citet{luce1977choice} choice axiom. Candidates with larger summed similarity are more likely to be generated compared to candidates with smaller summed similarity:
\begin{equation}
p(y) = \dfrac
    { exp( { \theta \cdot ss(y, x_j) } ) }
    { \sum_i{ exp( { \theta \cdot ss(y_i, x_j) } ) } }
\end{equation}
where $\theta$ ($\geq 0$) is a free parameter controlling overall response determinism. 

\subsubsection{Summary.}
The PACKER model described above explains exemplar and category generation through one of the field's oldest traditions: exemplar representations. The model proposes that people generate categories by maximizing within-category similarity and minimizing between-category similarity. Unlike the model proposed by \citet{jern2013probabilistic}, the distributional properties of known categories affects performance only insofar as it constrains inter-exemplar similarities. Instead, the \textit{location} of known categories in the domain is crucial because it constrains remaining possible locations for new categories. See Figure \ref{fig:example-prob-spaces} for a depiction of the model's behavior.

\begin{figure*}
    \begin{center}
    \inputpgf{figs/}{example-prob-spaces.pgf}
    \caption{Predicted generation of a category `B' example, following exposure to one member of category `A' and one member of category `B'. Areas in which generation is not likely are shaded white; high probability areas are shaded blue. \textit{Left}: Predictions given $\{\phi = 1$, $\gamma = 0\}$ (contrast influence only). \textit{Center}: Predictions given $\{\phi = 0$, $\gamma = 1\}$ (target influence only).  \textit{Right}: Predictions given $\{\phi = 1$, $\gamma = 1\}$ (both constraints considered).  }
    \label{fig:example-prob-spaces}
    \end{center}
\end{figure*}

\section{Behavioral Experiment}

The behavioral experiment described below was designed to test a core prediction of the PACKER model: that the \textit{location} of contrast categories (as opposed to their structure), influences generation. The experiment follows the paradigm set by \citet{jern2013probabilistic}. First, participants are exposed to members of a known category (`Alpha', or `A'), and are then asked to generate exemplars belonging to a new category (`Beta', or `B').

Because the goal of the study was to determine if the structure of known categories structure is the only determinant of generation, our experiment manipulated only the location of the Alpha category within the domain (the structure of the category was held constant). See Figure \ref{fig:middle-bottom-conditions} for a depiction of the experimental conditions. In both condition, members of the Alpha category are tightly clustered, with equal variance on both features and no correlation between features. The conditions differ only in the Y-Axis position of the Alpha category: in the `Middle' condition the Alpha category is placed in the center of the space, in the `Bottom' condition the Alpha category is placed in the bottom-center of the space. 

By consequence, the \citet{jern2013probabilistic} model predicts that there should be no difference in the structure of generated categories, as the distributional characteristics of the domain do not differ between the two conditions. Conversely, the PACKER model can predict strong between-condition differences. % What are the predictions---

\begin{figure}
    \begin{center}
    \input{figs/middle-bottom-conditions.pgf}
    \caption{Experiment conditions.}
    \label{fig:middle-bottom-conditions}
    \end{center}
\end{figure}


\subsection{Participants \& Materials}
\subsection{Procedure}
\subsection{Results}

\begin{itemize}
\item Following predictions of our exemplar model, the main interest was the use of space above and below the contrast category. [If-then logic]...
\item Obvious effects of category location: do people tend to place the new category somewhere else? See Figure \ref{fig:middle-bottom-yranges}, Table \ref{table:subset-table}.
\item The more interesting issue: does the remaining space constrain what types of categories people come up with? 
\item Analysis is tricky because vertical range is not normally distributed (see Figure \ref{fig:middle-bottom-yranges}). Report parametric / nonparametric stats.
\item Following core prediction of exemplar model, fewer participants used the top and bottom of the space when assigned the Bottom category, report 2x2x2 contingency table stats.
\item However, we also observed a great deal of individual differences in the form of ... [report types of categories, maybe show samples?]
%JLA: Yeah representative participants from each category and approximate size
\end{itemize}


\section{Simulations}
\section{Discussion}
\section{Acknowledgments}
%JLA: We have to add this... It's part of the deal with the funding that supports your salary
Support for this research was provided by the Office of the Vice Chancellor for Research and Graduate Education at the University of Wisconsin - Madison with funding from the Wisconsin Alumni Research Foundation.

\begin{figure*}
    \begin{center}
    \input{figs/middle-bottom-yranges.pgf}
    \caption{Behavioral results. Each line shows the minimum and maximum value of a generated category along the Y (vertical) axis. Dots along each line represent the positions of individual exemplars in the category, and each participant's category is shown on a separate line. Participants are sorted by overall Y axis range, and then by condition.}
    \label{fig:middle-bottom-yranges}
    \end{center}
\end{figure*}

\begin{table}[!ht]
\begin{center} 
\caption{Behavioral results.} 
\label{table:subset-table} 
\vskip 0.12in
\begin{tabular}{ l r r}
    \textbf{Middle}         & Used top rows & No top rows \\
    \hline
    Used bottom rows        &  31 & 18  \\
    No bottom rows          &  11 &  1  \\
    \\
    \textbf{Bottom}         & Used top rows & No top rows \\
    \hline
    Used bottom rows        & 22 & 8 \\
    No bottom rows          & 29 & 2 \\
\end{tabular}
\end{center} 
\end{table}




\bibliographystyle{apacite}
\setlength{\bibleftmargin}{.025in}
\setlength{\bibindent}{-\bibleftmargin}
\bibliography{references}

\end{document}
