%!TEX output_directory = latex_out/

\documentclass[10pt,letterpaper]{article}

\usepackage{cogsci}
\usepackage{pslatex}
\usepackage{mathtools}
\usepackage[natbibapa]{apacite}

%though some work has recently been conducted using traditional classification learning approaches . 
%Similar results were obtained in a more recent study conducted within a traditional categorization paradigm.

%each example's degree of contribution toward generation. PACKER sets according $f_j$ . $\hat{f_j} = \phi$ for known members of contrast categories, $\hat{f_j} = \gamma$ for members of the target category. 

%%Results such as these have motivated formal accounts of generation that explicitly invoke the idea that people re-purpose existing knowledge to generate something new -- either by copying-and-tweaking an observation retrieved from memory \citep{ward2002role,ward1995s}, or by abstracting the distributional structure of categories in the domain \citep{jern2013probabilistic}.

%Rather than evaluate PACKER on the benchmarks reviewed above, however, we instead focus on testing predictions made by PACKER that distinguish it from previous approaches.

%The attention weights are of interest in explaining individual differences in generation strategy (discussed below), but for our formal simulations they are set uniformly.

% so that is 1 when specifying whether $y$ exceeds the similarity threshold, $\tau$, which is treated as a free parameter ($0<\tau\leq1$). $g = 1$ when $s(y,z) < \tau$ and $g = 0$ otherwise. Thus, exemplars exceeding the similarity threshold will not be generated, but exemplars just under the threshold are most likely. \citet{jern2013probabilistic} did not implement any similarity threshold mechanism, and so their model is the special case where $\tau = 1$ (any exemplar may be selected).

%JLA: I took this one out because it's not really something we're dealing with in our paper.
%Further, exemplars drawn from the same species were less variable than animals drawn from different species, and possessed features that were adaptive for their environment (as is the case on Earth).



% set up PGF
\usepackage{pgfplots}
\pgfplotsset{compat=1.13}
\newcommand\inputpgf[2]{{
\let\pgfimageWithoutPath\pgfimage
\renewcommand{\pgfimage}[2][]{\pgfimageWithoutPath[##1]{#1/##2}}
\input{#1/#2}
}}


\title{PACKER: An Exemplar Model of Category Generation}

\author{
{ \large \bf Nolan Conaway (nconaway@wisc.edu) } \\
{ \large \bf Joseph L. Austerweil (austerweil@wisc.edu) } \\
Department of Psychology, 1202 W. Johnson Street \\
Madison, WI 53706 USA
}


\begin{document}

\maketitle

\begin{abstract}
FILLER (make very short)

\textbf{Keywords:} 
Categorization; etc
\end{abstract}

\section{Introduction}

One of the most intriguing capabilities of human cognition is the ability to generate new ideas and concepts. The creative creation of knowledge is an infrequent subject of formal inquiry. This paper focuses on one topic within creative cognition, category generation. Foundational work \citep[e.g.,][]{smith1993constraining,ward2002role,ward1994structured,ward1995s} found that people tend to create new categories that are similar to related previously known categories: New exemplars from the new categories tend to be copied from exemplars for a similar categories, but tweaked on one or a few dimensions. Thus, people generate a new category containing similar distributional properties to the categories it is based on, while being different from those categories in some manner. 

Existing work on the creative use of conceptual knowledge  explores the role of prior knowledge in generating novel concepts. A core phenomenon is that people generate new categories with similar distributional properties as existing categories. For example, \citet{ward1994structured} asked participants to draw and describe plants and animals that might exist on other planets. Generation was strongly constrained by prior knowledge of Earth plants and animals: People generated alien species with the same features as those found on Earth (e.g., eyes, legs, wings) and possessing the same feature correlations observed on Earth (e.g., feathers co-occur with wings). 


Recent work has proposed and tested computational models of how new categories are generated based on prior knowledge \citep{jern2013probabilistic}. In their experiments, they trained participants on a set of experimenter-defined categories composed of exemplars within an artificial three-dimensional domain (e.g., 2D shapes varying in size, hue, and saturation). After a short training phase, participants were asked to generate exemplars from a new category. Participants were provided with a set of scales to adjust the feature values of each generated stimulus, and were given unlimited time to create each example. As in the classic \cite{ward1994structured} experiment, \citet{jern2013probabilistic} found that people generated artificial categories possessing the same feature variance and correlations as the experimenter-defined categories in the domain. They evaluated different possible computational models of how people generate categories (such as "copy-and-tweak" and exemplar accounts) and found that a hierarchical Bayesian model generating new categories by abstracting the distributional structure of the categories in the domain.

%JLA: Add (a), (b) and (c) to figure and then use those to refer to each subpanel in the caption. It'll save space and be cleaner.
\begin{figure*}
    \begin{center}
    \inputpgf{figs/}{example-prob-spaces.pgf}
    \caption{PACKER generation of a category `B' example, following exposure to one member of category `A' and one member of category `B'. \textit{Left}: Predictions given $\{\phi = -1$, $\gamma = 0\}$ (contrast influence only). \textit{Center}: Predictions given $\{\phi = 0$, $\gamma = 1\}$ (target influence only).  \textit{Right}: Predictions given $\{\phi = -1$, $\gamma = 1\}$ (both constraints considered).  }
    \label{fig:example-prob-spaces}
    \end{center}
\end{figure*}

In this paper, we introduce a novel exemplar-based approach to category generation, the PACKER model (\textit{Producing Alike and Contrasting Knowledge using Exemplar Representations}), which creates new categories by balancing two constraints: (1) new categories should be different from known categories (minimizing between-class similarity), and (2) new categories should be internally coherent (maximizing within-class similarity). As such, PACKER is a significant departure from previous accounts of generation -- rather than proposing that people create new categories that are mostly similar to related categories, PACKER creates new categories that are different from related categories. Further, it does so using the well-studied mechanics of exemplar representations and therefore possesses a rich connection to the wider body of research on category learning.

In the sections below, we formally describe the PACKER model and explore its predictions in a behavioral experiment. We compare its performance to a copy-and-tweak and hierarchical Bayesian model by examining their fits to aggregate results and individual differences.

\section{PACKER: An Exemplar Model}

The PACKER model is an extension of the prominent Generalized Context Model of category learning (GCM; \citealp{nosofsky1984choice}). The model assumes that each category is represented by a collection of exemplars within in a $k$-dimensional psychological space, and that generation is constrained by both similarity to members of the target category (the category in which a stimulus is being generated) as well as similarity to members of other categories. 

As in the GCM, the similarity between two examples, $s\left(x_i, x_j\right)$, is an inverse-exponential function of distance:
\begin{equation}
  s\left(x_i,x_j\right) = \exp \left\{ -c \sum_{k}{ \left| x_{ik} - x_{jk} \right|}w_k \right\}
  \label{eq:similarity}
\end{equation}
where $w_k$ is the attention weighting of dimension $k$ ($w_k \geq 0$ and $\sum_k{w_k} = 1$), accounting for the relative importance of each dimension when calculating similarity, and $c$ ($c>0$) is a specificity parameter controlling the spread of exemplar generalization. For simplicity, most simulations will use uniform attention weights. We will use non-uniform attention weights in our discussion of individual differences.  


To generate a new example given examples from contrast and target categories, the model considers both the similarity to examples from the contrast category as well as the similarity to examples in the target category. The aggregated similarity $a$ between generation candidate $y$ and the model's stored exemplars $x$ can be computed as $a(y, x) = \sum_j{f(x_j) s(y, x_j)}$, where $f(x_j)$ is a function specifying the extent to which each exemplar contributes to the target category. For brevity, we will abbreviate $f(x_j)$ as $f_j$. PACKER sets $f_j$ depending on exemplar $j$'s category membership: $f_j = \phi$ if $x_j$ is a member of the contrast category, and $f_j = \gamma$ if $x_j$ is a member of the target category. $\phi$ and $\gamma$ are free parameters ($-\infty \leq \phi, \gamma \leq \infty$) controlling the contribution of contrast- and target-category similarity, respectively. Larger absolute values for either parameter produce greater consideration of that exemplar for generating the target category, with values of 0 producing no effect. A negative value for $f_j$ produces a `repelling' effect (target exemplars are less likely to be generated nearby $x_j$). Conversely, a positive value for $f_j$ produces a `pulling' effect (target exemplars are more likely to be generated nearby $x_j$). 

Recall that we proposed that categories are generated by balancing two constraints: that new categories should be different from existing categories, and exemplars belonging to the same category should be similar to one another. This is encoded in PACKER when $\phi < 0$, and $\gamma > 0$. Negative values for $\phi$ encourages $y$ to be distant from the contrast category (as similarity to contrast category exemplars are subtracted during aggregation). Positive values for $\gamma$ encourage $y$ to be close to other exemplars of the target category. When $|\phi| = \gamma$, the "force" of repulsion from the contrast category is equal to the "force" of attraction to the target category.

The probability that a given candidate $y$ will be generated is evaluated using an Exponentiated \citet{luce1977choice} choice rule. Candidates with greater values of $a$ are more likely to be generated than candidates with smaller values:
\begin{equation}
p(y) = \dfrac
    { \exp( { \theta \cdot a(y, x) } ) }
    { \sum_i{ \exp( { \theta \cdot a(y_i, x) } ) } }
    \label{eq:packer-choice}
\end{equation}
where $\theta$ ($\theta \geq 0$) controls response determinism. 

\subsection{Summary}
The proposed PACKER model suggests people generate categories by minimizing between-category similarity and maximizing within-category similarity. The underlying processes assumed by PACKER are highly similar to those in the GCM \citep{nosofsky1984choice}, with the only alteration being that PACKER aggregates positive- and negative-valued similarities, rather than only aggregating positive-valued similarities.

In later sections, we will explore the unique predictions yielded by these design principles. First, however, we contrast PACKER with other category generation models. 


\section{Previous Accounts of Category Generation}

Previous models of category generation focus on capturing the tendency for people to produce new categories that have similar distributional properties to existing categories. To the best of our knowledge, \citet{jern2013probabilistic} were the first to analyze behavioral results quantitatively to computational models. Based on their work, we describe two alternative models: a formalization of the \textit{copy-and-tweak} hypothesis \citep{ward2002role,ward1995s}, and the \textit{hierarchical sampling} proposed by \citet{jern2013probabilistic}.


\subsection{Copy-and-Tweak}
%JLA: PLEASE CHECK WHAT I WROTE TO MAKE SURE IT"S TRUE OF THEIR MODEL
The \textit{copy-and-tweak} model of \citet{jern2013probabilistic} formalizes one account of category generation \citep[see][]{ward2002role,ward1995s}. The model proposes that generation is a two-part process: First, learners retrieve an observation from memory, and then they tweak it to be different from the retrieved observation. \citet{jern2013probabilistic} interpreted this proposal in terms of an exemplar model, where participants score potential new exemplars as the summed exponentiated similarity of the potential new exemplar to every retrieved exemplar from the category, and sample from the normalized score distribution over potential exemplars. Given that this was intended for generating new exemplars within known category, we implemented a different formalization of the copy-and-tweak hypothesis.

In our implementation of the copy-and-tweak model, the probability that a given exemplar $z$ is retrieved from memory is $p(z) = \exp(f_z) / \sum_z{ \exp(f_z) }$, where $f_z$ is a function specifying each item's relative chance of being selected. In our simulations, we set $f_z$ to be $-\lambda$ for members of contrast categories, and $f_z = \lambda$ for members of the target category. The resulting free parameter $\lambda$ ($>0$) thus controls the relative chances that a member of the target category will be retrieved as the source. 
%\citet{jern2013probabilistic} did not implement any mechanisms to differentially weigh retrieval probabilities, and so our model encompasses theirs as a special case when $\lambda = 0$ (uniform probabilities). JLA: (i reread their model and i don't think this is quite true)

After a source exemplar is retrieved, the similarity between generation candidates $y$ and the retrieved exemplar is computed as per Equation \ref{eq:similarity}. The model's goal is to generate an item that is similar to $z$, but does not exceed a given similarity threshold: The generated item should be similar, but not too similar to $z$. Formally, the probability that candidate exemplar $y$ will be generated based on a source exemplar $z$ is 

\begin{equation}
    p(y|z)  = \dfrac
    { \exp \left\{\theta \cdot s(y,z) \right\} I\left(s(y,z) \leq \tau\right) }
    {\sum_i{\exp \left\{ \theta \cdot s(y_i,z) \right\} I\left(s(y_i,z) \leq \tau\right)}} 
\end{equation}
% 
where $\theta$ is a response determinism parameter, $\tau$ is the similarity threshold, and $I(\cdot)$ is the indicator function, which returns 1 when it is passed a true expression and 0 otherwise. So, $I\left(s(y,z) \leq \tau\right)$ is 1 when the candidate exemplar $y$ is far enough away from the source exemplar $z$. This ensures the source exemplar is tweaked "enough". When $\tau=1$, the threshold has no effect, which results in a model similar to \citet{jern2013probabilistic}. To obtain predictions not depending on a given source example, the model's predictions can be aggregated over all possible sources: $p(y) = \sum_z{p(z)p(y|z)}$.
%Thus, the probability that $y$ will be selected is a function of its generation probability given each of the sources, and the probability each source will be retrieved.

\subsection{Hierarchical Sampling}
% from other categories 
%with independently generated means, but correlated covariance matrices.
%Observed exemplars (represented as points in this space) are viewed as samples from their underlying category distribution (e.g., a multivariate normal distribution). These category distributions are in turn viewed as samples from an underlying domain distribution, which represents the common distributional characteristics among known categories (e.g., feature variance, feature correlations). When asked to generate a novel class, people are thought to sample a category distribution from the domain distribution, and then sample exemplars from the category distribution. Thus, exemplars generated into novel classes tend to obey the same distributional properties of known categories. 

Based on several results inconsistent with the copy-and-tweak account, \citet{jern2013probabilistic} advocated a hierarchical Bayesian model. Exemplars of each category were generated from a multivariate Gaussian distribution over the dimensions of stimulus space. The mean of each category was independent, but the covariance matrices (encoding feature variances and correlations) were generated from a common prior distribution. New categories are generated then by generating a new mean (uniform over stimulus space) and covariance matrix from the common prior distribution. Because the shared prior distribution's parameters were unobserved, a hierarchical Bayesian model uses information from the previous categories (their feature variances and correlations) to generate the covariance matrix of the new category.

We assume that each category's exemplars are distributed according to a multivariate normal distribution with parameters ($\mu, \Sigma$).\footnote{Following \citet{jern2013probabilistic} stimuli were put through a logistic function to constrain the domain to be between 0 and 1.} We assume that each category's covariance matrix is inverse-Wishart distributed with parameters ($v$, $\kappa,$ and $\Sigma_D$).\footnote{Note that \citet{jern2013probabilistic}'s model is slightly different, as they used a non-conjugate model. Their model acts very similar to our version of it and receives comparable fits.} $\Sigma_D$ is the covariance matrix shared between categories. We assumed the shared covariance matrix $\Sigma_D$ was generated from a Wishart distribution (for conjugacy) with parameters $v_0$, $\kappa_0$, and $\Sigma_0$. We set $\nu_0 = \kappa_0 = 1$, and $\Sigma_0 = \rho {\bf I}$, where $\rho$ was a free parameter controlling the expected variance of dimensions (dimensions of the shared covariance matrix are expected to be uncorrelated) and ${\bf I}$ is the identity matrix.

To simplify the model predictions, we used {\em maximum a posteriori} (MAP) estimates for the hidden parameters and then generated new categories based on those estimates. Due to conjugacy, the MAP estimate for the shared covariance matrix $\Sigma_D = \Sigma_0 + \sum_c{C_c}$, where $C_c$ is the empirical covariance matrix of category $c$. The MAP estimate of the covariance matrix for category $B$ is 
\begin{equation}
  \Sigma_B = \left[ \Sigma_D \nu + C_B +
    \dfrac
    {\kappa n_B}
    {\kappa + n_B}
    (\bar{x_B}-\mu_B)(\bar{x_B}-\mu_B)^T
  \right] (\nu + n_B)^{-1}
  \label{eq:Sigma_B}
\end{equation}
%
where $\nu$ ($\nu>k-1$) is an additional free parameter (from the Inverse-Wishart prior on $\Sigma_B$) weighting the importance of $\Sigma_{D}$. When the target category has no members, $\Sigma_B = \Sigma_D$.

Generated exemplars are then assumed to be drawn from the multivariate normal distribution specified by $(\mu_{B}, \Sigma_{B})$. Thus, $p(y)$ is
\begin{equation}
  p(y) = \dfrac
    {\exp( \theta \cdot {\rm Normal}(y; \mu_{B}, \Sigma_{B}))}
    {\sum_i \exp( \theta \cdot {\rm Normal}(y_i; \mu_{B}, \Sigma_{B}))} 
\end{equation}
where $\theta$ is a response determinism parameter and ${\rm Normal}(y; \mu, \Sigma)$ denotes a multivariate Normal density evaluated at $y$.
%JLA: There's something funky going on with the notation. I got confused by your noation, so hopefully you can update what i did to be consistent with the rest.
\section{Behavioral Experiment}
A novel prediction of PACKER is that the contrast category's location within stimulus space should influence the generated category -- the generated category should be repulsed from the contrast category. The other models predict the location of the contrast category within stimulus space should not influence the generated category. This experiment tests this prediction and quantitatively evaluates the three models.

%Whereas the copy-and-tweak and hierarchical sampling models both assume explicit mechanisms to re-purpose knowledge about known categories, the PACKER model forgoes these mechanisms entirely. Thus, whereas the distributional structure of observed categories will be the primary determinant of generation in the copy-and-tweak and hierarchical sampling models, these properties should only affect PACKER's generation insofar as they constrain inter-exemplar similarities. Instead, the \textit{location} of known categories in the domain is crucial because it constrains remaining possible locations for new categories.

The behavioral experiment described below was designed to test this key prediction:  Does the \textit{location} of contrast categories, influence generation? The experiment follows the paradigm developed by \citet{jern2013probabilistic}: first, participants learn members of a known category (`Alpha', or `A'), and are then asked to generate exemplars belonging to a new category (`Beta', or `B'). We developed two Alpha categories (see Figure \ref{fig:middle-bottom-conditions}). We did so by creating one of the Bottom Alpha category as a tight cluster and formed the Middle Alpha category by translating it to the center of stimulus space. As the two categories only differ in their location, the two categories should not differ in their distributional information.

%, instantiating the two conditions of the experiment. In both conditions, members of the Alpha category are tightly clustered, with equal feature variance and no feature correlations. Our manipulation is fairly `weak': the conditions have only a slight difference in the y-axis position of the Alpha category. In the `Middle' condition the Alpha category is placed in the center of the space, in the `Bottom' condition the Alpha category is placed in the bottom-center of the space. 

\begin{figure}
    \begin{center}
    \input{figs/middle-bottom-conditions.pgf}
    \caption{Conditions tested in the behavioral experiment.}
    \label{fig:middle-bottom-conditions}
    \end{center}
\end{figure}

Although our manipulation is minimal, the PACKER model is capable of predicting strong between-condition differences. PACKER proposes that the nature of the space not occupied by the Alpha category determines where members of the Beta category are likely to be generated. Thus, the lower areas of the stimulus space should be less frequently used for generation in the Bottom condition compared to the Middle (as these areas possess greater similarity to the Bottom Alpha category). Conversely, the upper areas of the stimulus space should be used for generation more frequently in the Bottom condition compared to Middle.

More generally, PACKER proposes that the probability a stimulus $y$ will be generated is a function of its similarity to contrast categories \textit{and} to members of the target category. Two more general predictions (not specific to either condition) follow from this proposal: (1) the location of Beta examples should be positively related to distance from the Alpha category, and (2) Beta examples should be more similar to one another than they are to members of the Alpha category.

\subsubsection{Participants \& Materials}
We recruited 122 participants from Amazon Mechanical Turk from the US equally assigned to each condition. Stimuli were squares varying in color (RGB 25--230) and size (3.0--5.8cm). The assignment of perceptual features (color, size) to axes of the domain space (x, y) was counterbalanced across participants.

\begin{figure}[ht!]
    \begin{center}
    \inputpgf{figs/}{beta.samples.pgf}
    \caption{Sample generated categories. }
    \label{fig:beta.samples}
    \end{center}
\end{figure}

\subsection{Procedure}

Participants began the experiment with a short training phase (3 blocks of 4 trials), where they observed exemplars belonging to the `Alpha' category. Participants were instructed to learn as much as they can about the Alpha category, and that they would answer a series of test questions afterwards. On each trial, a single Alpha category exemplar was presented, and participants were given as much time as they desired before moving on. Exemplars were randomly ordered within each block. Participants were shown the range of possible colors and sizes prior to training.

Following the training phase, participants were asked to generate four examples belonging to another category called `Beta'. Participants were instructed that members of the Beta category could be quite similar or different depending on what they think makes the most sense for the category, but that they were not allowed to make the same example twice. As in \citet{jern2013probabilistic}, generation was completed using a sliding-scale interface. Participants were presented with two scales that controlled the dimensions of the generated example. An on-screen preview of the example updated whenever one of the features was changed. Participants could generate any example along an evenly-spaced 9x9 grid, except for any previously generated Beta exemplars. Neither the members of the Alpha category nor the previously generated Beta examples were visible during generation. 

\subsection{Results}

Because the conditions differ only in their location along the y-axis (see Figure \ref{fig:middle-bottom-conditions}), we focus on how Beta exemplars are generated above and below the contrast category. Several sample Beta categories are depicted in Figure \ref{fig:beta.samples}. As is evident in Figure \ref{fig:beta.samples}, we observed a great deal of individual differences in generation strategy: Whereas some participants generated all four Beta examples within a narrow y-axis range, others generated Beta examples along a wide range. 

To evaluate the key predictions of PACKER, we determined the number of participants in each condition who placed at least one Beta examplar on the top and bottom `rows' of the space (the maximum and minimum possible y-axis value, respectively). The resulting contingencies data are shown in Table \ref{table:subset-table}. Fisher's Exact Tests reveal that more Middle participants generated a Beta exemplar in the bottom row , $p < 0.001$, but the conditions did not differ in use of the top of the space, $p = 0.16$. More Middle participants placed Beta exemplars in the top \textit{and} bottom rows, $p = 0.038$. 

\begin{table}
\begin{center} 
\label{table:subset-table} 
\vskip 0.12in
\begin{tabular}{ l r r}
    \textbf{Middle}         & Used top row & No top row \\
    \hline
    Used bottom rows       &  28 & 18  \\
    No bottom row          &  11 &  4  \\
    \\
    \textbf{Bottom}         & Used top row & No top row \\
    \hline
    Used bottom row        & 16 & 8 \\
    No bottom row          & 31 & 6 \\
\end{tabular}
\caption{Behavioral results.} 
\end{center} 
\end{table}
To evaluate PACKER's other predictions, we computed the number of exemplars produced at different distances to the center of the Alpha category. These data, depicted in the top panel of Figure \ref{fig:distance.figs} reveal a strong preference for stimuli that are dissimilar to the members of the Alpha category: maximally distant items were by far the most frequently generated. 

Finally, we computed for each participant the average distance between exemplars belonging to the same and opposite categories. These data (depicted in the bottom panel of Figure \ref{fig:distance.figs}) show that, as observed by \citet{ward1994structured}, most people generated Beta categories in which members are closer to one another than they are to members of the Alpha category (i.e., more between- than within-category distance). We did however, observe a notable subset of individuals with greater within-class distance. These individuals tended to adopt a `corners' approach, in which a Beta examples were placed almost exclusively in the corners of the space.

\begin{figure}
    \begin{center}
    \inputpgf{figs/}{distance.figs.pgf}
    \caption{Behavioral results. \textit{Top}: Frequency of exemplar generation as a function of distance from the Alpha category normalized by the maximum possible distance. \textit{Bottom}: Within- vs. between-category distance for every participant. }
    \label{fig:distance.figs}
    \end{center}
\end{figure}


\subsection{Summary}
Our results support PACKER's predictions: People tend to generate items that are dissimilar from the contrast category Alpha and similar to the target category Beta (with some exceptions, see Figure \ref{fig:distance.figs}). By consequence, we observed considerable differences in generation between the Middle and Bottom conditions: participants in the Bottom condition were less likely to use the bottom row of the stimulus space for generation, and participants in the Middle condition were more likely to create categories spanning the entire y-axis (utilizing the top and bottom row of the space). This latter result is especially interesting as it conflicts with previous results: Qualitatively different types of categories are generated (with very different distributional information), depending on only the location of the Alphas in the domain. 

The results described above are somewhat commonsense: they simply demonstrate that the location (rather than distributional structure) of existing categories imposes constraints on generation because people tend to generate examples in areas not occupied by existing categories. This principle, however, is not predicted by existing models of generation -- these models are instead designed to explain distributional correspondences between generated and existing categories.  


\section{Model Evaluation}
In this section, we evaluate the model fits to our results. To obtain an overall sense of each model's ability to explain our results, we fit each model by maximizing the log-likelihood of the model's predictions of the human results. Four free parameters were fitted in each model. The $c$, $\phi$, $\gamma$, and $\theta$ parameters were fitted for PACKER; $c$, $\lambda$, $\tau$, and $\theta$ were fitted for the copy-and-tweak model, and $\kappa$, $\rho$, $\nu$, and $\theta$ were fitted for the hierarchical sampling model. Note that each model possess a $\theta$ parameter fulfilling the same role (response determinism), and PACKER shares with copy-and-tweak a specificity parameter, $c$. Attention in PACKER and copy-and-tweak was set uniformly. Parameters were not allowed to vary between participants or conditions -- the goal was to obtain the best-fitting values to our entire dataset.

Each model's best-fitting parameterization is shown in Table \ref{table:model-fits}. Overall, PACKER outperformed copy-and-tweak and the hierarchical sampling model by a considerable margin ($\sim17\%$ improvement in log-likelihood). The parameter settings associated with PACKER's best fit are exactly as expected: a strong preference for items that are similar to members of the target category but are dissimilar to members of the contrast category. A similar pattern of results was obtained when we only considered the second to fourth exemplars generated by each participant.
%JLA this is fine
\begin{table}[ht!]
\centering
\caption{Model-fitting results.}
\label{table:model-fits}
\begin{tabular}{ l l l}
\\
 \textbf{PACKER} & \textbf{Copy \& Tweak} & \textbf{Hierarchical} \\
 & & \textbf{Sampling} \\ \hline
 $L = -1733$ & $L = -2040$ & $L = -2055$  \\ 
 $c=0.564$ & $c=9.445$  & $\kappa<0.001$\\
$\phi=-13.608$& $\lambda=15.115$ & $\rho=1.001$ \\ 
$\gamma=12.006$  & $\tau=0.415$ & $\nu=0.451$  \\ 
 $\theta=0.259$  & $\theta=7.068$ & $\theta=6.137$  \\ 
\end{tabular}
\end{table}

The model-fitting results above follow directly from the design of our experiment. Because distributional structure is the primary determinant of generation in the copy-and-tweak and hierarchical sampling models, those models have no basis to predict any differences between Middle and Bottom conditions (which do not differ in distributional structure). 

\subsection{Individual Differences}

Our behavioral results showed that, in general, generated categories consist of item that are (A) dissimilar to members of opposite categories, and (B) similar to members of the their own category. However, as shown in Figures \ref{fig:beta.samples} and \ref{fig:distance.figs}, we observed a great deal of individual differences in generation strategy. Four representative patterns of the generated Beta category were observed: tightly clustered, four corners, `column'-like categories (varying along the y-axis but not the x-axis), others created `row'-like categories. While it is important that any model be able to explain different types of performance with the same parameter values, these radical differences in generation are difficult to account for under a single set of parameters.

In future work, we intend to explore more systematically the role of PACKER's parameters in different subtypes of performance. For example, whereas the tight cluster profile could be explained with a moderately negative $\phi$ and a strongly positive $\gamma$, the four corners profile could be simulated with a strongly negative $\phi$ and $\gamma\leq0$. Here, we briefly explore the role of the attention weights ($w_1$ and $w_2$, in Equation \ref{eq:similarity}) in producing row-like or column-like categories.

\begin{figure}[ht!]
    \begin{center}
    \inputpgf{figs/}{range-diff-gradient.pgf}
    \caption{Generated category structure as a function of location in the domain. Orange areas in each gradient correspond to stimuli that were commonly generated into category possessing greater y-axis range (columns). Purple areas correspond to categories possessing greater x-axis range. White areas correspond to equal range along both features (or infrequent generation).}
    \label{fig:range-diff-gradient}
    \end{center}
\end{figure}

For each stimulus in the domain, we computed the difference in range between the features (e.g., $range(size) - range(color)$) across every generated category in which that stimulus was a member. Taking the average of these range differences yields a gradient describing how, on average, categories were distributed for each stimulus. These data, depicted in the top panels of Figure \ref{fig:range-diff-gradient} reveal a highly systematic relationship between category structure and category location. Whereas column-like categories more often include stimuli to the left or right of the Alpha class, row-like categories appear above and below the Alpha class.  Thus, even beyond generating Betas in locations not occupied by the Alphas, participants appear to modify the distributional structure of their categories in order to maximize distance from the Alphas.

To simulate this finding, we set the attention weight parameters in PACKER and copy-and-tweak separately for each participant. To simulate the hierarchical sampling model we set the domain covariance prior, $\Sigma_0$, separately for each participant. The other free parameters were set as in Table \ref{table:model-fits}. While there exist methods to find the optimal attention weights for a given classification \citep[see][]{vanpaemel2012using}, for ease of computation we simply approximated the weights based on the inverse of each feature's range: $w_k \propto range(k)^{-1}$. Thus, the Alpha and Beta categories are assumed to be distinct along dimensions that the Betas do not vary on. We then simulated 50 Beta categories with each participant's weighting scheme to obtain a sense of how the relative importance of each dimension affects what types of categories are generated and where they are generated. 

The results, depicted in Figure \ref{fig:range-diff-gradient}, support PACKER's predictions. When the x-axis is more strongly weighted, PACKER creates column categories to the sides of the Alphas. Conversely, when the y-axis is weighted, PACKER creates row categories above and below the Betas. This behavior falls out from the nature of selective attention: Dimensions with more weighting have a sharper similarity gradient. For example, when the x-axis is weighted more, PACKER favors Beta categories with more within-class similarity (less range), and less between-class similarity along the x-axis, resulting in column-like categories.

The hierarchical sampling and copy-and-tweak models do not often create categories with strong range differentials. However, when they do, the categories tend to show the opposite pattern: Columns are placed above and below the Alphas, rows are to the side of the Alphas. In the hierarchical sampling model, the position of contrast category is not considered when generating new items. Only the distributional structure of the contrast category and items already in the target category are considered. The model simulates row/column categories by assuming there is more x- or y-axis variance in the domain, essentially stretching the generated category distribution along that axis, and shrinking it along the opposite axis. However, because the Beta category distribution is centered in the middle of the space prior to the first trial, the model is most likely to generate items directly to the side of the Alphas if the x axis is weighted, or above/below the Alphas if the y-axis is weighted. Future generated items will follow from this distribution, and thus weighting the x-axis results row categories that possess the same y-axis position as the Alphas. Conversely, weighting the y-axis results in column categories that share the the same x-axis position as the Alphas.

The copy-and-tweak model operates by a similar principle. When, for example, the x-axis is weighted, the range of examples exceeding the similarity threshold ($\tau$) becomes much sharper along the x-axis (items need to be much closer to be considered at all similar), and broader along the y-axis. On the first trial, one of the Alphas will be used as a source, and because the similarity gradient is so sharp along the x-axis, the model will generate a Beta that is above or below the source. Future examples will follow this same pattern, resulting in a column category that differs from the alphas along the y-axis, as opposed to the x-axis.

\section{Discussion}
The creative use of conceptual knowledge is a fascinating yet understudied topic in categorization. In this paper, we presented a novel exemplar-based approach to explaining category generation. The PACKER model proposes that categories are represented as a collection of exemplars stored in memory, and that members of generated categories should be similar to one another, yet dissimilar to members of opposing categories. Given that exemplar models can be viewed as Importance-Sampling approximations of Bayesian models \citep{shi10}, PACKER can be viewed as a rational process model and approximating the expected density of a new category based on a contrast category. 

In a behavioral study and subsequent formal modeling, we found broad support for the PACKER model. Participants in our study more frequently generated items that are distant from members of contrast categories, and they tended to generate categories with more within-class than between-class similarity. Likewise, we found that the \textit{location} of contrast categories shapes generation by imposing constraints on the areas of space that remain available for a new category. Our formal simulations reveal that PACKER provides a strong account of our observations.

The PACKER model is, in general, highly expressive in its performance. Under different parameter settings it is capable of generating tightly clustered or highly distributed categories, and adjusting the distribution of categories along each feature. Future work will focus on exploring how individual differences in generation can be explained using PACKER, and whether the canonical effects observed by \citet{ward1994structured} and \citet{jern2013probabilistic} can be explained through exemplar-similarity alone.

\section{Acknowledgments}
Support for this research was provided by the Office of the VCRGE at the UW - Madison with funding from the WARF. We thank Kenneth Kurtz for helpful comments, and Alan Jern and Charles Kemp for providing code and data.
% any other thanks?



\bibliographystyle{apacite}
\setlength{\bibleftmargin}{.025in}
\setlength{\bibindent}{-\bibleftmargin}
\bibliography{references}

\end{document}
