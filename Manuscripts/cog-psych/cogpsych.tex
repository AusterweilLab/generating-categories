%!TEX output_directory = latex_out/

\documentclass[12pt]{article}
\usepackage[letterpaper, margin=1in, headheight=15pt]{geometry}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage{pgfplots}
\usepackage{fancyhdr}
\usepackage{csquotes}
\usepackage{todonotes}
\usepackage{verbatim}
\usepackage[natbibapa]{apacite}

% set up PGF
\pgfplotsset{compat=1.6}
\newcommand\inputpgf[2]{{
\let\pgfimageWithoutPath\pgfimage
\renewcommand{\pgfimage}[2][]{\pgfimageWithoutPath[##1]{#1/##2}}
\input{#1/#2}
}}

% set up notes-- different backgrounds for Nolan and Joe!
\newcommand\nbcnote[1]{\todo[inline, backgroundcolor = yellow]{\textbf{NBC}: #1}}
\newcommand\jlanote[1]{\todo[inline, backgroundcolor = lime]{\textbf{JLA}: #1}}

% set up header % 
\pagestyle{fancy}
\fancyhf{} % sets both header and footer to nothing
\renewcommand{\headrulewidth}{0pt}
\lhead{RUNNING HEAD: Similarity and Contrast in Concept Generation}
\fancyhead[R]{\thepage}


% author info:
% https://www.elsevier.com/journals/cognitive-psychology/0010-0285/guide-for-authors


\begin{document}



% ------- TITLE PAGE ------- %
\begin{center}
\hfill
\\[1in]

Creating Something Different: Similarity and Contrast in Concept Generation.
% ---- other ideas:
% - The Constraining Influences of Contrast and Similartity in Concept Generation.


\vfill

Nolan Conaway\textsuperscript{1}, 
Kenneth J. Kurtz\textsuperscript{2}, 
\& Joseph L. Austerweil\textsuperscript{1}
\\[\baselineskip]
\textsuperscript{1}University of Wisconsin-Madison, Department of Psychology, Madison, WI, USA
\textsuperscript{2}Department of Psychology, Binghamton University, Binghamton, NY, USA
\\[1in]

\vfill

Author Note

Correspondence concerning this article should be addressed to: 
Joseph Austerweil, 1202 West Johnson Street, Madison, WI 53706.
E-mail: austerweil@wisc.edu

\end{center}
\clearpage


% ------- ABSTRACT PAGE ------- %
\doublespacing
\section{Abstract}

\jlanote{Joe! Did you know i made a command for you to enter in comments like this?? }

\begin{verbatim}
    \jlanote{Some note}
\end{verbatim}


\setlength\parindent{0.5in}
\textit{Keywords}: categorization, concepts, creativity, generation
\clearpage


% ------- BEGIN! ------- %
\begin{flushleft}

\section{Introduction}
\setlength\parindent{0.5in}


The creation of novel concepts and ideas is a highly intriguing -- yet infrequently studied -- topic of research in human cognition. The creative use of conceptual knowledge is, for example, a core element of scientific investigation, wherein the generation of new ideas is critical to designing experiments and explaining observations. However, due to its complexity, little is presently known about the cognitive processes underlying the generation of new concepts. 

Much of what we know about concept generation comes from the foundational literature on creative cognition. In a classic series of reports, Ward \& colleagues \citep{ward1995s,ward1994structured,marsh1999inadvertent,ward2002role,smith1993constraining} established that category generation is highly constrained by prior knowledge: generated categories tend to consist of features observed in known categories, and they tend to exhibit the distributional properties as found in known categories. In a classic study, \cite{ward1994structured} asked participants to generate new species of alien animals by drawing and describing members of the species. People tended to generate species with the same features as on Earth (e.g., eyes, legs, wings), and possessing the same feature correlations as on Earth (e.g., feathers co-occur with wings). Likewise, aliens drawn from the same species tended to share more features with one another compared to members of opposite species. 

Much of the work from this area \citep[e.g.,][]{smith1993constraining,marsh1999inadvertent} focuses on how sample cues (such as an example of a species generated by other participants) can drastically diminish creativity. However, the broader set of observations made by Ward \& colleagues provide a great deal of insight into the nature of creative generation. They indicate that people rely strongly on prior knowledge in the creative process, and people generate concepts in accord with what they already know. 

Theoretical accounts of these effects have primarily been grounded within the categorization literature. For example, the predominant ``Path of Least Resistance'' account \citep[see][]{ward1994structured,ward1995s,ward2002role} proposes that, when generating a new species of animal, people retrieve from memory a known subcategory of animals (e.g., \textit{bird}, \textit{dog}, \textit{horse}), and simply change some of the features to make something new. People were thought to change only features that are not characteristic of the retrieved category (e.g., if \textit{bird} was retrieved, the presence of \textit{wings} would not change, but \textit{color} might). This theory incorporates elements of the highly influential basic-level categories framework \citep{rosch1975cognitive,rosch1976basic}, as well as the exemplar view \citep{medin1978context,nosofsky1984choice,nosofsky1986attention}. Problematically, however, the experimental paradigms employed in these studies were relatively uncontrolled, precluding the development of formal approaches. Specifically, participants in these studies are typically asked to generate objects that they have a rich degree of prior knowledge about (e.g., plants, animals, tools, toys), and so it is difficult to apply formal models to the data.

\cite{jern2013probabilistic} recently showed that creative generation could be studied in a more controlled manner through the well-developed methods of an artificial categorization paradigm \citep[see][]{kurtz2015human}. In their experiments 3 and 4, participants were exposed to members of experimenter-defined categories of "crystals" varying in size, hue, and saturation. Following a training phase during which the experimenter-defined categories were learned, participants were asked to generate novel categories of crystals. In a finding mirroring that of the \cite{ward1994structured} studies, \citeauthor{jern2013probabilistic} found that participants generated categories with the same distributional properties as the experimenter-defined categories: for example, after training on categories with a positive correlation between the size and saturation features (larger sized crystals were more saturated), participants generated novel categories with the same positive correlation. This finding is notable, as it demonstrates that category generation can be studied in a well-known and highly controlled experimental paradigm.

The authors evaluated the predictions of several formal models on their data. Most notably, they showed that a Bayesian hierarchical sampling model provided the strongest account. Their model represents categories as multivariate normal distributions within the space, and from exposure to category members the model induces a domain-wide representation of the distributional commonalities among the observed categories. When generating a new category, the model samples a new distribution from the domain, and thus the distributional properties of observed categories will be preserved within the generates category.

\nbcnote{Maybe we need a more technical view of the model here?}

\cite{jern2013probabilistic} additionally tested a "copy-and-tweak" model that broadly resembles the earlier "Path of Least Resistance" account: the core proposal is that participants generate new items by copying stored examples from memory and tweaking them to generate something new. The copy-and-tweak model differs from the path of least resistance account in that it notably omits the hierarchical organization of categories, as well as selectivity in which features are changed. Instead, their copy-and-tweak model corresponds to a direct exemplar-similarity approach \citep[e.g.,][]{nosofsky1984choice}: participants are thought to generate new items according to their similarity to known members of the target category. This model provided a poor account of the observed data: indeed, the experiments devised by \citeauthor{jern2013probabilistic} were specifically designed to challenge this model. However, it's application is notable as a first step toward explaining category generation using well-known formal approaches from the categorization literature.


\subsection{Something Different: A Role For Contrast}

It is worth noting that the literature reviewed above provides a somewhat limited view of category generation: the main concern of the published experiments has been on the distributional correspondences between learned and generated categories, and as a result most of the modeling efforts have been towards explaining those effects. In this paper, we investigate another important constraint on the creative use of conceptual knowledge: category contrast. In order to generate a novel concept, individuals must produce something that is in some capacity \textit{different} from what they already know. Thus, in a trivial sense, contrast can be viewed as a fundamental constraint on creative generation: new concepts must firstly be different from existing ones. 

Although it is evident that people are \textit{capable} of creating new concepts and categories, it is not entirely clear how new concepts are systematically made different from what is already known. The hierarchical sampling model developed by \cite{jern2013probabilistic}, for example, does not provide any strong claims about how generated categories should contrast with learned ones: the model only proposes that generated categories are sampled from the same underlying domain distribution as observed categories, and will thus share a common distributional structure. The authors do not make predictions about the \textit{location} of the category within the domain (the perceptual instantiation of category members). Indeed, under a strict interpretation of the hierarchical Bayesian approach, the generated category should actually overlap substantially with the known categories (as it's location is drawn based on those categories). Alternatively, the model's placement of the new category may simply be random (this was the case in the simulations conducted by \citeauthor{jern2013probabilistic}).

\nbcnote{Maybe tune that language to be more in line with the probabilistic world?}

The copy-and-tweak model tested by \cite{jern2013probabilistic} also claims little about how generated categories should contrast with what is already known. In their simulations, the model was only tested on generation after the learner had been exposed to members of the target category, and so the model's ability to generate a new category was not evaluated. However, the model's generation is based exclusively on similarity to known members of the target category; when there are no members of the target category, generation is presumably random.

\nbcnote{Maybe mention something about path of least resistance prediction that contrast is on non-characteristic dimensions? }

\subsection{Overview}

As noted in the sections above, research on the creative generation of novel concepts has thusfar focused on the finding that generated categories tend to possess distributional commonalities with known categories. However, a fundamental goal of concept generation is to create something \textit{new} (i.e., different from what is already known). The manner in which generated categories differ from known ones is, nonetheless, poorly understood: existing formal approaches do not make strong predictions about how creatively generated concepts should systematically differ from existing ones. 

In the sections below, we present two experiments demonstrating systematic effects of category contrast on creative generation. Our experiments conform strictly to the artificial category learning paradigm from \cite{jern2013probabilistic}: participants are first exposed to a single, experimenter-defined category, and are then asked to generate members of a new category. We also introduce a novel, exemplar-based model to explain these effects: PACKER (\textit{Producing Alike and Contrasting Knowledge using Exemplar Representations}). Finally, we report formal simulations comparing PACKER to the hierarchical sampling and copy-and-tweak models developed by \cite{jern2013probabilistic}.

\section{Experiment 1}

To begin our investigation, we developed a artificial, two dimensional domain of squares, varying in color and size (see Figure \ref{fig:sample-stimuli} for samples). We created three unique category types within this domain, shown in Figure \ref{fig:e1-conditions}. The category types were designed to possess strong differences in the distributional structure of the experimenter-defined (`A') category, allowing us to observe the effect of category contrast under a variety of types of prior knowledge. These conditions also provide an opportunity to replicate classic effects observed in previous reports \citep[e.g.,][]{jern2013probabilistic,ward1994structured,ward2002role,marsh1999inadvertent,smith1993constraining}.

\nbcnote{This feels a little weak in motivation: how do these conditions specifically allow us to show is these effects? Did we come up with these out of thin air? So maybe foreshadow that you hardly need to look for these effects, they're \textit{everywhere}. Maybe there is also a problem that at this point it is not exactly clear what contrast means within this scenario.}


\begin{figure}
    \begin{center}
    \inputpgf{figs/}{e1-conditions.pgf}
    \caption{Category types tested in Experiment 1.}
    \label{fig:e1-conditions}
    \end{center}
\end{figure}

In the `Cluster' type, the experimenter-defined category is a tight cluster of examples in the space (e.g., all members of category `A' are small and dark in color). In the `Row' type, the category has a row pattern across the space: varying along one feature but not the other (e.g., members of category `A' are small and vary in color). In the `XOR' type, the experiment-defined category consists of two clusters separated in opposite corners of the space category, conforming to the exclusive-or logical structure (e.g., members of category `A' can be small and dark or large and light). 




\subsection{Participants \& Materials}

183 participants were recruited from Amazon Mechanical Turk. Participants were randomly assigned to one condition: 64 participants were assigned to the Cluster condition, 61 were assigned to the Row condition, and 58 were assigned to the XOR condition. Stimuli were squares varying in color (RGB 25--230) and side length (3.0--5.8cm). These stimuli are slight variants of those used by \cite{conaway2016similar}, see Figure \ref{fig:sample-stimuli} for samples. The assignment of perceptual features (color, size) to axes of the domain space (x, y) was counterbalanced across participants.

\begin{figure}
    \begin{center}
    \inputpgf{figs/}{stimuli-samples.pgf}
    \caption{Sample stimuli used in Experiments 1 and 2.}
    \label{fig:sample-stimuli}
    \end{center}
\end{figure}

\subsection{Procedure}

Participants began the experiment with a short training phase (3 blocks of 4 trials), where they observed exemplars belonging to the `Alpha' category. Participants were instructed to learn as much as they can about the Alpha category, and that they would answer a series of test questions afterwards. On each trial, a single Alpha category exemplar was presented, and participants were given as much time as they desired before moving on. Each block consisted of a single presentation of each of the members of the Alpha category, in a random order. Participants were shown the range of possible colors and sizes prior to training.

Following the training phase, participants were asked to generate four examples belonging to another category called `Beta'. As in \citet{jern2013probabilistic}, generation was completed using a sliding-scale interface. Two scales controlled the features (color, size) of the generated example. An on-screen preview of the example updated whenever one of the features was changed. Participants could generate any example along an evenly-spaced 9x9 grid, except for any previously generated Beta exemplars. Neither the members of the Alpha category nor the previously generated Beta examples were visible during generation. Prior to beginning the generation phase, participants read the following instructions:

\begin{displayquote}
As it turns out, there is another category of geometric figures called ``Beta''. Instead of showing you examples of the Beta category, we would like to know what you think is likely to be in the Beta category. 

You will now be given the chance to create examples of any size or color in order to show what you expect about the Beta category. You will be asked to produce 4 Beta examples - they can be quite similar or quite different to each other, depending on what you think makes the most sense for the category.

Each example needs to be unique, but the computer will let you know if you accidentally create a repeat.
\end{displayquote}

Following generation, participants completed a generalization phase wherein they classified novel examples into the Alpha and Beta categories without feedback. On each trial, a single example was presented, and participants were asked to classify it by clicking buttons labeled ``Alpha'' or ``Beta''. Participants classified a total of 81 items sampled along a 9x9 grid, including the members of the Alpha and Beta categories (randomly intermixed). These data were, however, collected to address a separate set of questions, and we do not discuss them in this paper.




\clearpage

\section{Experiment 2}


\begin{figure}
    \begin{center}
    \input{figs/e2-conditions.pgf}
    \caption{Category types tested in Experiment 2.}
    \label{fig:e2-conditions}
    \end{center}
\end{figure}

We developed two Alpha categories (see Figure \ref{fig:e2-conditions}): the `Bottom' category is a tight cluster in the bottom-center of the space, and the `Middle' category is identical except that it lies in the center of stimulus space. Although this manipulation is minimal (the conditions differ only slightly in the Y-axis position of the experimenter-defined category), the PACKER model predicts strong between-condition differences. According to PACKER, the nature of the space not occupied by the existing categories should determine where members of the Beta category are likely to be generated. Thus, the lower areas of the stimulus space should be less frequently used for generation in the Bottom condition compared to the Middle (as these areas possess greater similarity to the Bottom category). Conversely, the upper areas of the stimulus space should be used for generation more frequently in the Bottom condition compared to Middle.


\subsection{Participants \& Materials}

122 participants were recruited from Amazon Mechanical Turk. 61 participants were randomly assigned to the Middle and Bottom conditions each. The stimuli were exactly as in Experiment 1. Again, the assignment of perceptual features (color, size) to axes of the domain space (x, y) was counterbalanced across participants.

\subsection{Procedure}

The procedure was exactly as in Experiment 1: participants first completed a short training phase, followed by the generation phase, followed by the generalization phase (data from this phase is not discussed in this report).












\clearpage

\section{The PACKER Model}

The PACKER model is an extension of the influential Generalized Context Model of category learning \citep[GCM;][]{nosofsky1984choice,nosofsky1986attention}. The GCM simulates categorization under the assumption that learners represent categories as a collection of exemplars, corresponding to the labeled stimuli they have observed. The exemplars are encoded within a $k$-dimensional psychological space, and categorization is based on the amount of similarity between the item to be categorized and the stored exemplars. Similarity between two examples, $s\left(x_i, x_j\right)$, is computed as an inverse exponential function of distance \citep[following][]{shepard1957stimulus,shepard1987toward}:

\begin{equation}
  s\left(x_i,x_j\right) = \exp \left\{ -c \left[\sum_{k}{ w_k \left| x_{ik} - x_{jk} \right|^r }\right]^{1/r} \right\}
  \label{eq:similarity}
\end{equation}
% 
where $w_k$ is the attention weighting of dimension $k$ ($w_k \geq 0$ and $\sum_k{w_k} = 1$), accounting for the relative importance of each dimension in similarity calculations, and $c$ ($c>0$) is a specificity parameter controlling the spread of exemplar generalization. For simplicity, attention will be distributed uniformly in our simulations (unless otherwise noted). The value of $r$ depends on the nature of the experimental conditions being simulated: $r=1$ is appropriate for separable dimensions, whereas $r=2$ is appropriate for integral dimensions \citep[see][]{shepard1964attention,garner1974processing}.


PACKER's core proposal (as well as its name) was in part inspired by earlier work from category learning literature \citep[see][]{hidaka2011packing}. PACKER proposes that generation is constrained by both similarity to members of the target category (the category in which a stimulus is being generated) as well as similarity to members of other categories: the most desirable generation candidates are similar to members of the target category and not similar to members of contrast categories. This is achieved by aggregating similarity across known exemplars differently according to class membership. The aggregated similarity $a$ between generation candidate $y$ and stored exemplars $x$ is given by:

\begin{equation}
    a(y, x) = \sum_j{f(x_j) s(y, x_j)}
\end{equation}
% 
where $f(x_j)$ is a function specifying each exemplar's contribution to generation. PACKER sets $f(x_j)$ depending on exemplar $x_j$'s category membership: $f(x_j) = \phi$ if $x_j$ is a member of a contrast category, and $f(x_j) = \gamma$ if $x_j$ is a member of the target category. $\phi$ and $\gamma$ are free parameters ($-\infty \leq \phi, \gamma \leq \infty$) controlling the contribution of contrast- and target-category similarity, respectively. Larger absolute values result in greater consideration of those exemplars, with values of 0 eliminating their effect. A negative value for $f(x_j)$ produces a `repelling' effect (exemplars are less likely to be generated nearby $x_j$). Conversely, a positive value for $f(x_j)$ produces an `attracting' effect (exemplars are more likely to be generated nearby $x_j$). 

\begin{figure}
    \begin{center}
    \inputpgf{figs/}{packer-examples.pgf}
    \caption{PACKER generation of a category `B' example, following exposure to one member of category `A' and one member of category `B'. Predictions are shown for three different parameterizations: \textit{(a)} Predictions based on contrast similarity only. \textit{(b)} Predictions based on target similarity only.  \textit{(c)} Predictions with both constraints considered.}
    \label{fig:packer-examples}
    \end{center}
\end{figure}

As noted above, PACKER proposes that new categories should be different from existing categories, and same-category exemplars should be similar to one another. This is realized when $\phi \leq 0$, and $\gamma \geq 0$. Negative $\phi$ values encourage $y$ to be distant from contrast categories (as similarity to contrast category exemplars are subtracted during aggregation). Positive $\gamma$ values encourage $y$ to be close to other exemplars of the target category. When $|\phi| = \gamma$, the repulsion effect from contrast categories is equal to the attraction effect to the target category. See Figure \ref{fig:packer-examples} for an illustration of how these parameters are used.

The probability that a given candidate $y$ will be generated is evaluated using an Exponentiated \citet{luce1977choice} choice rule. Candidates with greater values of $a$ are more likely to be generated than candidates with smaller values:
% 
\begin{equation}
p(y) = \dfrac
    { \exp  \left \{ \theta \cdot a \left( y, x \right) \right \} } 
    { \sum_i{ \exp  \left \{ \theta \cdot a \left( y_i, x \right) \right\}  } }
    \label{eq:packer-choice}
\end{equation}
% 
where $\theta$ ($\theta \geq 0$) is a free parameter controlling response determinism. 

\nbcnote{It is worth noting that PACKER is not the only \textit{possible} model that could incorporate a contrast mechanism. However, contrast falls out naturally from the exemplar view and ...  Contrast could, for example, be implemented within... }

\subsection{Relation Between PACKER and Copy-And-Tweak}

The PACKER model is in many senses similar to the copy-and-tweak model reported by \cite{jern2013probabilistic}: both models are exemplar-based, and both models generate new items according to their similarity to known members of the target class. PACKER diverges from from the copy-and-tweak model only in the inclusion of a contrast mechanism, enabling generation according to dissimilarity to members of opposing categories. By consequence, copy-and-tweak can be realized as a parameterization of the PACKER model that is insensitive to category contrast. Specifically, when $\phi = 0$ and $\gamma = 1$ (see Figure \ref{fig:packer-examples}, panel B), PACKER is not influenced by similarity to members of opposite categories, and is mathematically equivalent to a copy-and-tweak approach.

In this paper, we report simulations using this copy-and-tweak model. The model we test is identical to PACKER, under the constraints that $\phi = 0$ and $\gamma = 1$, and is a continuous-dimension adaptation of the model tested by \cite{jern2013probabilistic}. Due to their mathematical equivalence, the comparison between PACKER and copy-and-tweak provides a test of the explanatory value of the contrast mechanism: the account provided by copy-and-tweak will only equal that of PACKER if the contrast mechanism does not offer an advantage.


\subsection{The Hierarchical Sampling Model}

\cite{jern2013probabilistic} demonstrated how a hierarchical Bayesian model could explain the distributional correspondences between observed and generated categories. In their model, exemplars of generated category were viewed as samples from a multivariate Normal distribution over the dimensions of stimulus space. The mean of the generated category was independent of the observed categories, but the covariance matrix (encoding feature variances and correlations) was based on a common prior distribution. Generating a new category was thus completed by sampling a new category mean (uniform over stimulus space) and covariance matrix from the common prior distribution. Because the shared prior distribution's parameters were unobserved, the hierarchical Bayesian approach was used to infer its parameters from the previous categories (their feature variances and correlations), and then to generate the covariance matrix of the new category.

In our implementation of their model, each category's exemplars are assumed to be sampled from a multivariate Normal distribution with parameters ($\mu, \Sigma$). Each category's covariance matrix is assumed to be inverse-Wishart distributed with parameters ($v$, $\kappa,$ and $\Sigma_D$).\footnote{Note that \citet{jern2013probabilistic}'s model is slightly different, as they used a non-conjugate model. Their model acts very similar to our version of it and receives comparable fits.} $\Sigma_D$ is the covariance matrix shared between categories. We assume the shared covariance matrix $\Sigma_D$ is generated from a Wishart distribution (for conjugacy) with parameters $v_0$, $\kappa_0$, and $\Sigma_0$. We set $\nu_0 = 4$, and $\Sigma_0 = \rho {\bf I}$, where $\rho$ is a free parameter controlling the expected variance of dimensions (dimensions of the shared covariance matrix are expected to be uncorrelated) and ${\bf I}$ is the identity matrix.

\nbcnote{check on that $\nu_0 = 4$ business}

To simplify the model predictions, we used {\em maximum a posteriori} (MAP) estimates for the hidden parameters and then generated new categories based on those estimates. Due to conjugacy, the MAP estimate for the shared covariance matrix $\Sigma_D = \Sigma_0 + \sum_c{C_c}$, where $C_c$ is the empirical covariance matrix of category $c$. The MAP estimate of the covariance matrix for the target category $B$ is 
\begin{equation}
  \Sigma_B = \left[ \Sigma_D \nu + C_B +
    \dfrac
    {\kappa n_B}
    {\kappa + n_B}
    (\bar{x}_B-\mu_B)(\bar{x}_B-\mu_B)^T
  \right] (\nu + n_B)^{-1}
  \label{eq:Sigma_B}
\end{equation}
%
where $\nu$ ($\nu>k-1$) is an additional free parameter (from the Inverse-Wishart prior on $\Sigma_B$) weighting the importance of $\Sigma_{D}$. When the target category has no members (i.e., $n_B = 0$), items are generated at random.

\nbcnote{should explain Equation \ref{eq:Sigma_B} more fully now that we are not limited for space.}

Generated exemplars are drawn from a multivariate Normal distribution specified by $(\mu_{B}, \Sigma_{B})$. Thus, $p(y)$ is
\begin{equation}
  p(y) = \dfrac
    {\exp \left \{ \theta \cdot {\rm Normal}(y; \mu_{B}, \Sigma_{B}) \right \} }
    {\sum_i \exp \left \{ \theta \cdot {\rm Normal}(y_i; \mu_{B}, \Sigma_{B}) \right \} } 
\end{equation}
where $\theta$ is a response determinism parameter and ${\rm Normal}(y; \mu, \Sigma)$ denotes a multivariate Normal density evaluated at $y$. 


\section{Acknowledgments}
A previous version of this work appeared in the Proceedings of the Thirty-Ninth Annual Conference of the Cognitive Science Society. Support for this research was provided by the Office of the VCRGE at the UW - Madison with funding from the WARF. We thank Alan Jern and Charles Kemp for providing code and data.



\end{flushleft}


% references section
\clearpage
\bibliographystyle{apacite}
\bibliography{citations.bib}
\clearpage



\end{document}
