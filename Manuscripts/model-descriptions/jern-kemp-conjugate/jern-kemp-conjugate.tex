%!TEX output_directory = latex_out/

\documentclass[12pt]{article}
\usepackage[letterpaper, margin=1in, headheight=15pt]{geometry}
\usepackage{amsmath,fancyvrb}



\begin{document}
\VerbatimFootnotes

\section*{Updated Version of the Jern \& Kemp (2013) Model}

Working backwards, what is needed for simulation of exemplar generation is the probability of generating a stimulus $x$ given exposure to members of the target category $x_b$:
\
\begin{equation}
p(x | x_b) = ?
\end{equation}
\
where $x_b$ may be empty. Jern \& Kemp's model achieves this using a generative process. Category members ($x_a$ or $x_b$; more generally written as $x_y$) are assumed to have been generated using an underlying category distribution (specifically, multivariate normal):
\
\begin{equation}
  x_y \sim Normal(\mu_{y}, \Sigma_{y})
\end{equation}
\
$p(x | x_y)$ is proportional to the candidate's density under the target category's distribution. Thus, obtaining the category distribution parameters $(\mu_{y}, \Sigma_{y})$ is key for generation. This document describes how we compute these variables in a conjugate model. 

\subsection*{Computing $\mu_y$}
Assuming $(\mu_y, \Sigma_y)$ are Normal-Inverse-Wishart distributed (unknown mean, unknown variance):
\
\begin{equation}
  \mu_y = \dfrac
    {\kappa\mu_{0} + n_y \bar{x_y}}
    {\kappa + n_y}
    \label{eq:category_mus}
\end{equation}
\ 
where:
\begin{itemize}
    \setlength\itemsep{-0.5em}
    \item $\mu_{0}$ is the prior mean along $p$ dimensions. Here we set it to the middle of the space.
    \item $\kappa$ is a scalar hyper-parameter, roughly weighting the importance of $\mu_{0}$. $\kappa$ must be greater than zero.
    \item $n_y$ is the number of observations in $x_y$
    \item $\bar{x_y}$ is the sample mean along $p$ dimensions
\end{itemize}

In the case of a populated class, $\mu_{y}$ ends up lying somewhere between $\mu_{0}$ and $\bar{x_y}$, depending on $\kappa_{0}$ and $n_y$. In the case of an empty class, $n_y = 0$, thus Equation \ref{eq:category_mus} reduces to $\mu_{y} = \mu_{0}$. Because we set $\mu_0$ to the center of the space, this outcome is the same as if we had integrated over all possible $\mu_y$.


\subsection*{Computing $\Sigma_D$}

Unlike $\mu_y$, $\Sigma_y$ cannot be computed considering only the members of category $y$. Instead, $\Sigma_y$ is influenced both by the distribution of $x_y$ and by members of other categories through $\Sigma_D$.

$\Sigma_D$ is inferred based on the observed (empirical) category covariances $C_y$. We assume these covariances to be Wishart-distributed, and so $\Sigma_D$ can be computed as:

\
\begin{equation}
    \Sigma_D = \Sigma_0 + \sum_{y}{C_y}
\end{equation}
\
$\Sigma_{0}$ is a $p$-by-$p$ prior covariance matrix. We use a $p$-dimensional identity matrix $I_p$ multiplied element-wise against a free parameter, $\gamma$, controlling the amount of variance assumed by the prior:
\
\begin{equation}
    \Sigma_0 =  I_p\gamma
\end{equation}

Thus, categories are assumed to have some degree of variance along each feature (specified by $\gamma$), but not are assumed to possess feature-feature correlations.

\subsection*{Computing $\Sigma_y$}

Assuming $(\mu_y, \Sigma_y)$ are Normal-Inverse-Wishart distributed, $\Sigma_y$ can be computed as:

\begin{equation}
  \Sigma_y = [\Sigma_D\nu + C_y +
    \dfrac
    {\kappa n_y}
    {\kappa + n_y}
    (\bar{x_y}-\mu_y)(\bar{x_y}-\mu_y)^T
  ] (\nu + n_y)^{-1}
  \label{eq:Sigma_y}
\end{equation}
\
$\kappa$, $\bar{x_y}$, $C_y$, $n_y$, $\mu_0$,  are the same values as described above. $\nu$ is an additional free parameter, weighting the importance of $\Sigma_{D}$. $\nu$ must be greater than $p-1$. When $x_b$ is empty, Equation \ref{eq:Sigma_y} reduces to $\Sigma_y = \Sigma_D$. 

\subsection*{Computing response probabilities $p(x | x_b)$}

$x$ are assumed to be drawn from a the distribution given by $Normal(\mu_{y}, \Sigma_{y})$. Thus, 


\begin{equation}
  p(x) \propto Normal(x | \mu_{b}, \Sigma_{b})
\end{equation}

In practice, $p(x)$ is computed by first obtaining the relative density of every possible generation candidate $x_i$ under the category distribution. The end probability is a normalization of these values:

\begin{equation}
  p(x) = \dfrac
    {exp( \theta Normal(x | \mu_{b}, \Sigma_{b}))}
    {\sum_i exp( \theta Normal(x_i |\mu_{b}, \Sigma_{b}))} 
\end{equation}
\
where $\theta$ is a response determinism parameter.

\subsection*{Description of free parameters}

\begin{itemize}
    \setlength\itemsep{-0.5em}
    \item $\kappa$. Scalar, $\kappa>0$. Weights the importance of $\mu_{0}$ in inferring category $\mu_{y}$.
    \item $\gamma$. Scalar, $\gamma>0$. Weights the importance of $\Sigma_{0}$ in inferring the domain $\Sigma_{D}$.
    \item $\nu$. Scalar, $\nu > p-1$. Weights the importance of $\Sigma_{D}$ in inferring the domain $\Sigma_{y}$.
    \item $\theta$. Scalar, $\theta > 0$. Response determinism parameter.
\end{itemize}



\end{document}
